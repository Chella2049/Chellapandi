{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO+ISpadr9TnPF9Dqpfajld",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Chella2049/Chellapandi/blob/main/Assign_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "iJ0Oqf5JNELk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import gradio as gr\n",
        "from mlxtend.frequent_patterns import apriori, association_rules\n",
        "\n",
        "# Function to process CSV and apply Apriori\n",
        "def generate_association_rules(file, min_support, min_confidence):\n",
        "    df = pd.read_csv(file.name)\n",
        "\n",
        "    # Convert categorical data into transaction format\n",
        "    df = df.applymap(lambda x: str(x).strip())  # Ensure proper formatting\n",
        "    transactions = df.values.tolist()\n",
        "    unique_items = sorted(set(item for sublist in transactions for item in sublist if item))\n",
        "\n",
        "    # Create one-hot encoded DataFrame\n",
        "    encoded_data = pd.DataFrame([[1 if item in row else 0 for item in unique_items] for row in transactions], columns=unique_items)\n",
        "\n",
        "    # Apply Apriori Algorithm\n",
        "    frequent_itemsets = apriori(encoded_data, min_support=min_support, use_colnames=True)\n",
        "    rules = association_rules(frequent_itemsets, metric=\"confidence\", min_threshold=min_confidence)\n",
        "\n",
        "    return rules[['antecedents', 'consequents', 'support', 'confidence', 'lift']].to_string(index=False)\n",
        "\n",
        "# Gradio Interface\n",
        "demo = gr.Interface(\n",
        "    fn=generate_association_rules,\n",
        "    inputs=[gr.File(), gr.Slider(0.01, 1.0, step=0.01, label=\"Min Support\"), gr.Slider(0.1, 1.0, step=0.05, label=\"Min Confidence\")],\n",
        "    outputs=gr.Textbox(label=\"Association Rules\"),\n",
        "    title=\"Apriori Algorithm - Association Rule Mining\",\n",
        "    description=\"Upload a CSV file containing transaction data. The Apriori algorithm will generate association rules based on the chosen parameters.\"\n",
        ")\n",
        "\n",
        "demo.launch()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 680
        },
        "id": "J1bFEznkNEos",
        "outputId": "8323afe6-5df3-468f-e254-494b57e358b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/uvicorn/protocols/websockets/websockets_impl.py:17: DeprecationWarning: websockets.server.WebSocketServerProtocol is deprecated\n",
            "  from websockets.server import WebSocketServerProtocol\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Gradio in a Colab notebook requires sharing enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://743bac11010706ab54.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://743bac11010706ab54.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Dense\n",
        "from sklearn.cluster import KMeans\n",
        "import gradio as gr\n",
        "\n",
        "# Load sample movie ratings dataset (assumed to be in user-item matrix format)\n",
        "def load_sample_data():\n",
        "    data = {\n",
        "        'User1': [5, 4, 0, 1, 0],\n",
        "        'User2': [4, 5, 1, 0, 0],\n",
        "        'User3': [0, 0, 5, 4, 3],\n",
        "        'User4': [0, 1, 4, 5, 2],\n",
        "        'User5': [3, 3, 4, 5, 5],\n",
        "    }\n",
        "    df = pd.DataFrame(data, index=['Movie A', 'Movie B', 'Movie C', 'Movie D', 'Movie E'])\n",
        "    return df.T\n",
        "\n",
        "ratings = load_sample_data()\n",
        "n_users, n_movies = ratings.shape\n",
        "\n",
        "# Autoencoder model\n",
        "input_layer = Input(shape=(n_movies,))\n",
        "encoded = Dense(4, activation='relu')(input_layer)\n",
        "encoded = Dense(2, activation='relu')(encoded)  # Latent space (compressed representation)\n",
        "decoded = Dense(4, activation='relu')(encoded)\n",
        "decoded = Dense(n_movies, activation='sigmoid')(decoded)\n",
        "\n",
        "autoencoder = Model(input_layer, decoded)\n",
        "autoencoder.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "# Train autoencoder\n",
        "X_train = ratings.fillna(0).values  # Replace NaN with 0\n",
        "autoencoder.fit(X_train, X_train, epochs=100, batch_size=2, verbose=0)\n",
        "\n",
        "# Extract user embeddings\n",
        "encoder = Model(input_layer, encoded)\n",
        "user_embeddings = encoder.predict(X_train)\n",
        "\n",
        "# Cluster users using K-Means\n",
        "n_clusters = 2  # Define number of clusters\n",
        "kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
        "kmeans.fit(user_embeddings)\n",
        "user_clusters = kmeans.labels_\n",
        "\n",
        "# Function to recommend movies based on user clustering\n",
        "def recommend_movies(user_ratings):\n",
        "    user_ratings = np.array([float(x) for x in user_ratings.split(',')])\n",
        "    user_embedding = encoder.predict(user_ratings.reshape(1, -1))\n",
        "    cluster = kmeans.predict(user_embedding)[0]\n",
        "    cluster_users = ratings.iloc[np.where(user_clusters == cluster)]\n",
        "    avg_ratings = cluster_users.mean().sort_values(ascending=False)\n",
        "    return avg_ratings.index.tolist()\n",
        "\n",
        "# Gradio Interface\n",
        "demo = gr.Interface(\n",
        "    fn=recommend_movies,\n",
        "    inputs=gr.Textbox(placeholder=\"Enter ratings as comma-separated values, e.g., 5,4,0,1,0\"),\n",
        "    outputs=gr.Textbox(label=\"Recommended Movies\"),\n",
        "    title=\"Deep Learning Movie Recommender\",\n",
        "    description=\"Enter your movie ratings (comma-separated). The system will cluster you with similar users and recommend movies accordingly.\"\n",
        ")\n",
        "\n",
        "demo.launch()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 663
        },
        "id": "TsfH5qtMU364",
        "outputId": "ee53c512-93ea-4ef2-995e-2fe276332704"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step\n",
            "Running Gradio in a Colab notebook requires sharing enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://166f9f9c11378266ae.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://166f9f9c11378266ae.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import nltk\n",
        "from nltk.sentiment import SentimentIntensityAnalyzer\n",
        "from sklearn.cluster import KMeans\n",
        "import gradio as gr\n",
        "\n",
        "# Download VADER sentiment analyzer\n",
        "nltk.download('vader_lexicon')\n",
        "sia = SentimentIntensityAnalyzer()\n",
        "\n",
        "# Sample dataset: Social media comments\n",
        "data = {\n",
        "    'User': ['User1', 'User2', 'User3', 'User4', 'User5', 'User6', 'User7'],\n",
        "    'Comment': [\n",
        "        \"I love this product! Absolutely amazing!\",  # Positive\n",
        "        \"Worst experience ever. Never buying again!\",  # Negative\n",
        "        \"It's okay, nothing special but not bad either.\",  # Neutral\n",
        "        \"Fantastic service, very satisfied!\",  # Positive\n",
        "        \"I hate it, total waste of money!\",  # Negative\n",
        "        \"Mediocre at best, but decent value.\",  # Neutral\n",
        "        \"Superb quality, exceeded expectations!\"  # Positive\n",
        "    ]\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Sentiment Analysis Function\n",
        "def analyze_sentiment(text):\n",
        "    scores = sia.polarity_scores(text)\n",
        "    return [scores['neg'], scores['neu'], scores['pos']]\n",
        "\n",
        "# Convert comments to sentiment scores\n",
        "df[['Negative', 'Neutral', 'Positive']] = df['Comment'].apply(analyze_sentiment).apply(pd.Series)\n",
        "\n",
        "# Apply K-Means clustering\n",
        "n_clusters = 3  # Positive, Neutral, Negative\n",
        "kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
        "df['Cluster'] = kmeans.fit_predict(df[['Negative', 'Neutral', 'Positive']])\n",
        "\n",
        "# Function to predict sentiment cluster for new comments\n",
        "def predict_cluster(comment):\n",
        "    sentiment_scores = np.array(analyze_sentiment(comment)).reshape(1, -1)\n",
        "    cluster = kmeans.predict(sentiment_scores)[0]\n",
        "    cluster_labels = {0: 'Negative', 1: 'Neutral', 2: 'Positive'}\n",
        "    return f\"Predicted Sentiment: {cluster_labels[cluster]}\"\n",
        "\n",
        "# Gradio Interface\n",
        "demo = gr.Interface(\n",
        "    fn=predict_cluster,\n",
        "    inputs=gr.Textbox(placeholder=\"Enter a comment...\"),\n",
        "    outputs=gr.Textbox(label=\"Sentiment Cluster\"),\n",
        "    title=\"Sentiment-Based Clustering for Opinion Analysis\",\n",
        "    description=\"Enter a social media comment, and the system will analyze its sentiment and categorize it into a cluster (Positive, Neutral, Negative).\"\n",
        ")\n",
        "\n",
        "demo.launch()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 663
        },
        "id": "wS_0HHJgWS34",
        "outputId": "8dd9ea17-4603-4f5d-d770-97d87d3ebab1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Gradio in a Colab notebook requires sharing enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://655bccab988fcf9208.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://655bccab988fcf9208.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import folium\n",
        "from folium.plugins import MarkerCluster\n",
        "from sklearn.cluster import KMeans\n",
        "import gradio as gr\n",
        "\n",
        "# Sample Crime Dataset (Latitude, Longitude, Crime Type)\n",
        "data = {\n",
        "    'Latitude': [37.7749, 37.7750, 37.7755, 37.7800, 37.7700, 37.7790, 37.7760],\n",
        "    'Longitude': [-122.4194, -122.4185, -122.4175, -122.4160, -122.4205, -122.4150, -122.4140],\n",
        "    'Crime Type': ['Theft', 'Assault', 'Burglary', 'Robbery', 'Theft', 'Vandalism', 'Assault']\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Function to perform K-Means clustering and generate hotspot map\n",
        "def generate_crime_map(n_clusters):\n",
        "    kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
        "    df['Cluster'] = kmeans.fit_predict(df[['Latitude', 'Longitude']])\n",
        "\n",
        "    # Create Map\n",
        "    crime_map = folium.Map(location=[df['Latitude'].mean(), df['Longitude'].mean()], zoom_start=13)\n",
        "    colors = ['red', 'blue', 'green', 'purple', 'orange', 'darkred', 'lightred']  # Colors for clusters\n",
        "\n",
        "    # Add clustered crime locations to the map\n",
        "    marker_cluster = MarkerCluster().add_to(crime_map)\n",
        "    for i, row in df.iterrows():\n",
        "        folium.Marker(\n",
        "            location=[row['Latitude'], row['Longitude']],\n",
        "            popup=f\"{row['Crime Type']} - Cluster {row['Cluster']}\",\n",
        "            icon=folium.Icon(color=colors[row['Cluster'] % len(colors)])\n",
        "        ).add_to(marker_cluster)\n",
        "\n",
        "    return crime_map._repr_html_()\n",
        "\n",
        "# Gradio Interface\n",
        "demo = gr.Interface(\n",
        "    fn=generate_crime_map,\n",
        "    inputs=gr.Slider(minimum=1, maximum=5, step=1, value=3, label=\"Number of Clusters\"),\n",
        "    outputs=gr.HTML(label=\"Crime Hotspot Map\"),\n",
        "    title=\"Crime Hotspot Detection Using K-Means\",\n",
        "    description=\"Adjust the number of clusters to analyze crime hotspots.\"\n",
        ")\n",
        "\n",
        "demo.launch()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        },
        "id": "-Ofsxf6eYorS",
        "outputId": "93f2e110-fd3d-4d09-d8c5-334919ea915b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Gradio in a Colab notebook requires sharing enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://52db71a3c92fede701.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://52db71a3c92fede701.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    }
  ]
}